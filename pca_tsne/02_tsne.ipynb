{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns (Missing Values): ['dfire2_total']\n",
      "Dropped columns (Correlation): ['num_residues', 'rosetta_rama_prepro', 'budeff_charge', 'evoef2_interD_total', 'rosetta_lk_ball_wtd', 'aggrescan3d_total_value', 'rosetta_fa_intra_sol_xover4', 'rosetta_fa_sol', 'budeff_steric', 'mass', 'evoef2_intraR_total', 'rosetta_fa_rep', 'evoef2_ref_total', 'rosetta_pro_close', 'rosetta_fa_atr', 'rosetta_p_aa_pp', 'rosetta_hbond_sr_bb', 'rosetta_hbond_lr_bb', 'rosetta_hbond_bb_sc', 'charge', 'evoef2_total', 'rosetta_fa_intra_rep', 'evoef2_interS_total', 'budeff_desolvation', 'rosetta_fa_elec', 'rosetta_fa_dun', 'rosetta_hbond_sc']\n",
      "Dropped columns (Little/no Variance): ['Class number', 'S100 sequence cluster number', 'S100 sequence count number', 'Architecture number', 'composition_UNK', 'S60 sequence cluster number', 'architecture_name', 'S95 sequence cluster number', 'rosetta_yhh_planarity']\n",
      "Total number of datapoints for beta_barrel (2,40): 1100\n",
      "TSNE analysis completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Load the dataset\n",
    "\n",
    "path = \"/Volumes/dax-hd/project-data/search-files/merged-data.csv\"\n",
    "base_save_folder = \"/Volumes/dax-hd/project-data/images/tsne_topology_2/\"\n",
    "cath_dict_path = \"/Volumes/dax-hd/project-data/search-files/cath-archetype-dict.txt\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "original_columns = set(df.columns)\n",
    "\n",
    "with open(cath_dict_path, 'r') as file:\n",
    "    cath_dict = json.load(file)\n",
    "if not os.path.exists(base_save_folder):\n",
    "    os.makedirs(base_save_folder)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "selected_architectures = [\"beta_barrel (2,40)\"]\n",
    "\n",
    "destress_columns = [\n",
    "    \"hydrophobic_fitness\",\n",
    "    \"isoelectric_point\",\n",
    "    \"charge\",\n",
    "    \"mass\",\n",
    "    \"num_residues\",\n",
    "    \"packing_density\",\n",
    "    \"budeff_total\",\n",
    "    \"budeff_steric\",\n",
    "    \"budeff_desolvation\",\n",
    "    \"budeff_charge\",\n",
    "    \"evoef2_total\",\n",
    "    \"evoef2_ref_total\",\n",
    "    \"evoef2_intraR_total\",\n",
    "    \"evoef2_interS_total\",\n",
    "    \"evoef2_interD_total\",\n",
    "    \"dfire2_total\",\n",
    "    \"rosetta_total\",\n",
    "    \"rosetta_fa_atr\",\n",
    "    \"rosetta_fa_rep\",\n",
    "    \"rosetta_fa_intra_rep\",\n",
    "    \"rosetta_fa_elec\",\n",
    "    \"rosetta_fa_sol\",\n",
    "    \"rosetta_lk_ball_wtd\",\n",
    "    \"rosetta_fa_intra_sol_xover4\",\n",
    "    \"rosetta_hbond_lr_bb\",\n",
    "    \"rosetta_hbond_sr_bb\",\n",
    "    \"rosetta_hbond_bb_sc\",\n",
    "    \"rosetta_hbond_sc\",\n",
    "    \"rosetta_dslf_fa13\",\n",
    "    \"rosetta_rama_prepro\",\n",
    "    \"rosetta_p_aa_pp\",\n",
    "    \"rosetta_fa_dun\",\n",
    "    \"rosetta_omega\",\n",
    "    \"rosetta_pro_close\",\n",
    "    \"rosetta_yhh_planarity\",\n",
    "    \"aggrescan3d_total_value\",\n",
    "    \"aggrescan3d_avg_value\",\n",
    "    \"aggrescan3d_min_value\",\n",
    "    \"aggrescan3d_max_value\"\n",
    "    ]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Add the architecture name to df\n",
    "\n",
    "def add_topology_description(df, cath_dict):\n",
    "    def get_topology_description(row):\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            description = cath_dict[class_num][arch_num][top_num]['description']\n",
    "            return description\n",
    "        except KeyError:\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    df['topology_description'] = df.apply(get_topology_description, axis=1)\n",
    "    return df\n",
    "\n",
    "df = add_topology_description(df, cath_dict)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Removing correlating features\n",
    "\n",
    "def remove_highly_correlated_features(df, tolerance, columns):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "\n",
    "    valid_columns = [col for col in columns if col in df.columns and np.issubdtype(df[col].dtype, np.number)]\n",
    "    df_selected = df[valid_columns].copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df_selected)\n",
    "    df_scaled = pd.DataFrame(scaled_features, columns=valid_columns)\n",
    "\n",
    "    corr_matrix = df_scaled.corr(method='spearman').abs()\n",
    "    dropped_features = []\n",
    "\n",
    "    while True:\n",
    "        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > tolerance)]\n",
    "        \n",
    "        if not to_drop:\n",
    "            break\n",
    "        \n",
    "        feature_to_remove = to_drop[0]\n",
    "        df_selected.drop(columns=feature_to_remove, inplace=True)\n",
    "        df_scaled.drop(columns=feature_to_remove, inplace=True)\n",
    "        dropped_features.append(feature_to_remove)\n",
    "        corr_matrix = df_scaled.corr(method='spearman').abs()\n",
    "\n",
    "    return df.drop(columns=dropped_features), dropped_features\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Remove missing data\n",
    "\n",
    "threshold = 0.2\n",
    "missing_percentage = df.isnull().sum() / len(df)\n",
    "columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "df = df.drop(columns=columns_to_drop, axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "cleaned_columns = set(df.columns)\n",
    "dropped_columns = list(original_columns - cleaned_columns)\n",
    "print(\"Dropped columns (Missing Values):\", dropped_columns)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Normalise Data\n",
    "\n",
    "normalise_columns = [\n",
    "    \"num_residues\", \"hydrophobic_fitness\", \"budeff_total\", \"budeff_steric\", \"budeff_desolvation\", \"budeff_charge\",\n",
    "    \"evoef2_total\", \"evoef2_ref_total\", \"evoef2_intraR_total\", \"evoef2_interS_total\", \"evoef2_interD_total\",\n",
    "    \"dfire2_total\", \"rosetta_total\", \"rosetta_fa_atr\", \"rosetta_fa_rep\", \"rosetta_fa_intra_rep\", \"rosetta_fa_elec\",\n",
    "    \"rosetta_fa_sol\", \"rosetta_lk_ball_wtd\", \"rosetta_fa_intra_sol_xover4\", \"rosetta_hbond_lr_bb\",\n",
    "    \"rosetta_hbond_sr_bb\", \"rosetta_hbond_bb_sc\", \"rosetta_hbond_sc\", \"rosetta_dslf_fa13\", \"rosetta_rama_prepro\",\n",
    "    \"rosetta_p_aa_pp\", \"rosetta_fa_dun\", \"rosetta_omega\", \"rosetta_pro_close\", \"rosetta_yhh_planarity\"\n",
    "]\n",
    "\n",
    "if 'num_residues' in df.columns:\n",
    "    for field in normalise_columns:\n",
    "        if field in df.columns:\n",
    "            df[field] = df[field] / df['num_residues']\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Drop mass and residue number, removing highly correlated features, and scaling\n",
    "            \n",
    "df = df[df['architecture_name'].isin(selected_architectures)]\n",
    "\n",
    "df = df.drop(['mass', 'num_residues'], axis=1)\n",
    "\n",
    "df, dropped_features = remove_highly_correlated_features(df, tolerance=0.6, columns=destress_columns)\n",
    "\n",
    "corr_columns = set(df.columns)\n",
    "dropped_columns_corr = list(cleaned_columns - corr_columns)\n",
    "print(\"Dropped columns (Correlation):\", dropped_columns_corr)\n",
    "\n",
    "nunique = df.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "nuq_columns = set(df.columns)\n",
    "dropped_columns_nuq = list(corr_columns - nuq_columns)\n",
    "print(\"Dropped columns (Little/no Variance):\", dropped_columns_nuq)\n",
    "\n",
    "tsne_columns = [col for col in destress_columns if col in df.columns]\n",
    "df_tsne_ready = df[tsne_columns].dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_tsne_ready)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Plotting\n",
    "\n",
    "for architecture_name in selected_architectures:\n",
    "    save_folder = os.path.join(base_save_folder, architecture_name.replace('/', '_'))\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=20, learning_rate=800, n_iter=3000, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(df_scaled)\n",
    "    tsne_df = pd.DataFrame(data=tsne_results, columns=['Dimension 1', 'Dimension 2'])\n",
    "    \n",
    "    tsne_df['topology_description'] = df['topology_description'].values[:len(tsne_df)]\n",
    "    print(f\"Total number of datapoints for {architecture_name}: {len(tsne_df)}\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    tsne_df['topology_description'] = df['topology_description'].values\n",
    "    unique_topologies = tsne_df['topology_description'].unique()\n",
    "    topology_to_id = {topology: i % 3 for i, topology in enumerate(unique_topologies)}\n",
    "\n",
    "    tsne_df['marker_style'] = tsne_df['topology_description'].map(topology_to_id).map({0: 'o', 1: '^', 2: 's'})\n",
    "\n",
    "    markers = ['o', '^', 's']\n",
    "    palette = sns.color_palette('Spectral', n_colors=len(unique_topologies))\n",
    "    \n",
    "    plt.figure(figsize=(20, 12))\n",
    "    ax = plt.subplot(111, aspect='equal')\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x='Dimension 1', y='Dimension 2',\n",
    "        hue='topology_description',\n",
    "        style='marker_style',\n",
    "        palette=palette,\n",
    "        markers=markers,\n",
    "        data=tsne_df, s=100,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    plt.title(f't-SNE for {architecture_name}')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "\n",
    "    ax.legend_.remove()\n",
    "    legend_items = []\n",
    "    for i, (topology, marker) in enumerate(zip(unique_topologies, markers * (len(unique_topologies) // len(markers) + 1))):\n",
    "        legend_items.append(mlines.Line2D([], [], color=palette[i % len(palette)], marker=marker, linestyle='None', markersize=10, label=topology))\n",
    "    ax.legend(handles=legend_items, title='Topology Description', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "    plt.figtext(0.5, 0.03, f\"Perplexity: {tsne.perplexity}, Learning Rate: {tsne.learning_rate}, Iterations: {tsne.n_iter}\", ha=\"center\", fontsize=10)\n",
    "    plt.figtext(0.5, 0.01, f\"Features used: {tsne_columns}\", ha=\"center\", fontsize=10)\n",
    "        \n",
    "    plt.savefig(os.path.join(save_folder, f\"{architecture_name}-tsne.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"TSNE analysis completed.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Load the dataset\n",
    "\n",
    "path = \"/Volumes/dax-hd/project-data/corr_features/destress_columns_reduced.csv \"\n",
    "base_save_folder = \"/Volumes/dax-hd/project-data/images/tsne_topology_\"\n",
    "cath_dict_path = \"/Volumes/dax-hd/project-data/search-files/cath-archetype-dict.txt\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "with open(cath_dict_path, 'r') as file:\n",
    "    cath_dict = json.load(file)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Add the architecture name to df\n",
    "\n",
    "def add_topology_description(df, cath_dict):\n",
    "    def get_topology_description(row):\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            description = cath_dict[class_num][arch_num][top_num]['description']\n",
    "            return description\n",
    "        except KeyError:\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    df['topology_description'] = df.apply(get_topology_description, axis=1)\n",
    "    return df\n",
    "\n",
    "df = add_topology_description(df, cath_dict)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def filter_for_archetypes(df, cath_dict):\n",
    "    archetype_ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            protein_id = cath_dict[class_num][arch_num][top_num]['protein_id']\n",
    "            if protein_id[:4] in row['design_name']:\n",
    "                archetype_ids.append(row['design_name'])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return df[df['design_name'].isin(archetype_ids)]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "selected_architectures = [\"sandwich (2,60)\"]\n",
    "\n",
    "selected_columns = [\n",
    "    \"hydrophobic_fitness\",\n",
    "    \"isoelectric_point\",\n",
    "    \"charge\",\n",
    "    \"mass\",\n",
    "    \"num_residues\",\n",
    "    \"packing_density\",\n",
    "    \"budeff_total\",\n",
    "    \"budeff_steric\",\n",
    "    \"budeff_desolvation\",\n",
    "    \"budeff_charge\",\n",
    "    \"evoef2_total\",\n",
    "    \"evoef2_ref_total\",\n",
    "    \"evoef2_intraR_total\",\n",
    "    \"evoef2_interS_total\",\n",
    "    \"evoef2_interD_total\",\n",
    "    \"dfire2_total\",\n",
    "    \"rosetta_total\",\n",
    "    \"rosetta_fa_atr\",\n",
    "    \"rosetta_fa_rep\",\n",
    "    \"rosetta_fa_intra_rep\",\n",
    "    \"rosetta_fa_elec\",\n",
    "    \"rosetta_fa_sol\",\n",
    "    \"rosetta_lk_ball_wtd\",\n",
    "    \"rosetta_fa_intra_sol_xover4\",\n",
    "    \"rosetta_hbond_lr_bb\",\n",
    "    \"rosetta_hbond_sr_bb\",\n",
    "    \"rosetta_hbond_bb_sc\",\n",
    "    \"rosetta_hbond_sc\",\n",
    "    \"rosetta_dslf_fa13\",\n",
    "    \"rosetta_rama_prepro\",\n",
    "    \"rosetta_p_aa_pp\",\n",
    "    \"rosetta_fa_dun\",\n",
    "    \"rosetta_omega\",\n",
    "    \"rosetta_pro_close\",\n",
    "    \"rosetta_yhh_planarity\",\n",
    "    \"aggrescan3d_total_value\",\n",
    "    \"aggrescan3d_avg_value\",\n",
    "    \"aggrescan3d_min_value\",\n",
    "    \"aggrescan3d_max_value\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "df_filtered = df #filter_for_archetypes(df, cath_dict)\n",
    "df_selected_cleaned = df_filtered[selected_columns].dropna()\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_selected_cleaned)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "for architecture_name in df['architecture_name'].unique():\n",
    "    if architecture_name not in selected_architectures:\n",
    "        continue\n",
    "\n",
    "    df_architecture = df[df['architecture_name'] == architecture_name]\n",
    "    df_selected_cleaned = df_architecture[selected_columns].dropna()\n",
    "\n",
    "    if df_selected_cleaned.empty:\n",
    "        print(f\"No data available for {architecture_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    topology_descriptions = df_architecture['topology_description'][df_selected_cleaned.index].reset_index(drop=True)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df_selected_cleaned)\n",
    "\n",
    "    tsne = TSNE(n_components=3, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(scaled_features)\n",
    "    \n",
    "    tsne_df = pd.DataFrame(tsne_results, columns=['Dimension 1', 'Dimension 2', 'Dimension 3'])\n",
    "    tsne_df['topology_description'] = topology_descriptions\n",
    "\n",
    "    # 3D Plotting\n",
    "    fig = plt.figure(figsize=(30, 21))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    codes, uniques = pd.factorize(tsne_df['topology_description'])\n",
    "\n",
    "    num_colors = len(uniques)\n",
    "\n",
    "    repeated_cmap = plt.cm.tab20c(np.linspace(0, 1, num_colors) % 1)\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        tsne_df['Dimension 1'], tsne_df['Dimension 2'], tsne_df['Dimension 3'],\n",
    "        c=[repeated_cmap[i] for i in codes],\n",
    "        s=100\n",
    "    )\n",
    "\n",
    "    legend_handles = [mpatches.Patch(color=repeated_cmap[i], label=uniques[i]) for i in range(num_colors)]\n",
    "\n",
    "    ax.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Topologies\")\n",
    "\n",
    "    ax.set_title(f't-SNE 3D Visualization')\n",
    "    ax.set_xlabel('Dimension 1')\n",
    "    ax.set_ylabel('Dimension 2')\n",
    "    ax.set_zlabel('Dimension 3')\n",
    "\n",
    "    figure_path = os.path.join(base_save_folder, f\"tsne_3d_{architecture_name}.png\")\n",
    "    plt.savefig(figure_path)\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1oai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m             continue_removal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_reduced\n\u001b[0;32m---> 32\u001b[0m df_reduced, dropped_features \u001b[38;5;241m=\u001b[39m \u001b[43mremove_highly_correlated_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduced DataFrame shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_reduced\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropped features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dropped_features)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mremove_highly_correlated_features\u001b[0;34m(df, tolerance)\u001b[0m\n\u001b[1;32m     10\u001b[0m df_reduced \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m dropped_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 13\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf_reduced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mabs()\n\u001b[1;32m     15\u001b[0m continue_removal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m continue_removal:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/frame.py:11036\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11034\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11035\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11036\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11039\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/frame.py:1981\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1980\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1981\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1692\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1751\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1751\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1752\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1oai'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
