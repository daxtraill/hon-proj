{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of datapoints for alpha_beta_roll (3,10): 1225\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Load the dataset\n",
    "\n",
    "path = \"/Volumes/dax-hd/project-data/corr_features/destress_columns_reduced.csv\"\n",
    "base_save_folder = \"/Volumes/dax-hd/project-data/images/tsne_topology_reduced/\"\n",
    "cath_dict_path = \"/Volumes/dax-hd/project-data/search-files/cath-archetype-dict.txt\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "with open(cath_dict_path, 'r') as file:\n",
    "    cath_dict = json.load(file)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Add the architecture name to df\n",
    "\n",
    "def add_topology_description(df, cath_dict):\n",
    "    def get_topology_description(row):\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            description = cath_dict[class_num][arch_num][top_num]['description']\n",
    "            return description\n",
    "        except KeyError:\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    df['topology_description'] = df.apply(get_topology_description, axis=1)\n",
    "    return df\n",
    "\n",
    "df = add_topology_description(df, cath_dict)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def filter_for_archetypes(df, cath_dict):\n",
    "    archetype_ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            protein_id = cath_dict[class_num][arch_num][top_num]['protein_id']\n",
    "            if protein_id[:4] in row['design_name']:\n",
    "                archetype_ids.append(row['design_name'])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return df[df['design_name'].isin(archetype_ids)]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "selected_architectures = [\"alpha_beta_roll (3,10)\"]\n",
    "\n",
    "selected_columns = [\n",
    "    \"hydrophobic_fitness\",\n",
    "    \"isoelectric_point\",\n",
    "    \"charge\",\n",
    "    \"mass\",\n",
    "    \"packing_density\",\n",
    "    \"evoef2_interD_total\",\n",
    "    \"rosetta_total\",\n",
    "    \"rosetta_hbond_sc\",\n",
    "    \"rosetta_dslf_fa13\",\n",
    "    \"rosetta_pro_close\",\n",
    "    \"rosetta_yhh_planarity\",\n",
    "    \"aggrescan3d_avg_value\",\n",
    "    \"aggrescan3d_min_value\",\n",
    "    \"aggrescan3d_max_value\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "df_filtered = df\n",
    "df_selected_cleaned = df_filtered[selected_columns].dropna()\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_selected_cleaned)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "for architecture_name in df['architecture_name'].unique():\n",
    "    if architecture_name not in selected_architectures:\n",
    "        continue\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_filtered_architecture = df[df['architecture_name'] == architecture_name]\n",
    "    df_selected = df_filtered_architecture[selected_columns]\n",
    "    df_selected_cleaned = df_selected.dropna()\n",
    "    \n",
    "    if df_selected_cleaned.empty:\n",
    "        continue\n",
    "\n",
    "    topology_descriptions = df_filtered_architecture['topology_description'][df_selected_cleaned.index].reset_index(drop=True)\n",
    "\n",
    "    save_folder = os.path.join(base_save_folder, architecture_name.replace('/', '_'))\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df_selected_cleaned)\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=800, n_iter=3000, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(scaled_features)\n",
    "    tsne_df = pd.DataFrame(data=tsne_results, columns=['Dimension 1', 'Dimension 2'])\n",
    "\n",
    "    tsne_df['topology_description'] = topology_descriptions.values\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------\n",
    "    # Plotting\n",
    "\n",
    "    print(f\"Total number of datapoints for {architecture_name}: {len(tsne_df)}\")\n",
    "    \n",
    "    unique_topologies = tsne_df['topology_description'].unique()\n",
    "    palette = sns.color_palette('Spectral', n_colors=len(unique_topologies))\n",
    "    topology_color_mapping = {topology: color for topology, color in zip(unique_topologies, palette)}\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    scatter_plot = sns.scatterplot(\n",
    "        x='Dimension 1', y='Dimension 2',\n",
    "        hue='topology_description',\n",
    "        palette=topology_color_mapping,\n",
    "        data=tsne_df, s=100\n",
    "    )\n",
    "    plt.title(f't-SNE for {architecture_name}')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "\n",
    "    handles, labels = scatter_plot.get_legend_handles_labels()\n",
    "    plt.legend([],[], frameon=False)\n",
    "    plt.savefig(os.path.join(save_folder, 'tsne_scatter_by_topology.png'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    fig_legend = plt.figure(figsize=(3, 4))\n",
    "    plt.figlegend(handles, labels, loc='center')\n",
    "    plt.savefig(os.path.join(save_folder, 'legend.png'), bbox_inches='tight')\n",
    "    plt.close(fig_legend)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Load the dataset\n",
    "\n",
    "path = \"/Volumes/dax-hd/project-data/corr_features/destress_columns_reduced.csv \"\n",
    "base_save_folder = \"/Volumes/dax-hd/project-data/images/tsne_topology_\"\n",
    "cath_dict_path = \"/Volumes/dax-hd/project-data/search-files/cath-archetype-dict.txt\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "with open(cath_dict_path, 'r') as file:\n",
    "    cath_dict = json.load(file)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "# Add the architecture name to df\n",
    "\n",
    "def add_topology_description(df, cath_dict):\n",
    "    def get_topology_description(row):\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            description = cath_dict[class_num][arch_num][top_num]['description']\n",
    "            return description\n",
    "        except KeyError:\n",
    "            return \"Unknown\"\n",
    "    \n",
    "    df['topology_description'] = df.apply(get_topology_description, axis=1)\n",
    "    return df\n",
    "\n",
    "df = add_topology_description(df, cath_dict)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "def filter_for_archetypes(df, cath_dict):\n",
    "    archetype_ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        class_num = str(row['Class number'])\n",
    "        arch_num = str(row['Architecture number'])\n",
    "        top_num = str(row['Topology number'])\n",
    "        try:\n",
    "            protein_id = cath_dict[class_num][arch_num][top_num]['protein_id']\n",
    "            if protein_id[:4] in row['design_name']:\n",
    "                archetype_ids.append(row['design_name'])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return df[df['design_name'].isin(archetype_ids)]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "selected_architectures = [\"sandwich (2,60)\"]\n",
    "\n",
    "selected_columns = [\n",
    "    \"hydrophobic_fitness\",\n",
    "    \"isoelectric_point\",\n",
    "    \"charge\",\n",
    "    \"mass\",\n",
    "    \"num_residues\",\n",
    "    \"packing_density\",\n",
    "    \"budeff_total\",\n",
    "    \"budeff_steric\",\n",
    "    \"budeff_desolvation\",\n",
    "    \"budeff_charge\",\n",
    "    \"evoef2_total\",\n",
    "    \"evoef2_ref_total\",\n",
    "    \"evoef2_intraR_total\",\n",
    "    \"evoef2_interS_total\",\n",
    "    \"evoef2_interD_total\",\n",
    "    \"dfire2_total\",\n",
    "    \"rosetta_total\",\n",
    "    \"rosetta_fa_atr\",\n",
    "    \"rosetta_fa_rep\",\n",
    "    \"rosetta_fa_intra_rep\",\n",
    "    \"rosetta_fa_elec\",\n",
    "    \"rosetta_fa_sol\",\n",
    "    \"rosetta_lk_ball_wtd\",\n",
    "    \"rosetta_fa_intra_sol_xover4\",\n",
    "    \"rosetta_hbond_lr_bb\",\n",
    "    \"rosetta_hbond_sr_bb\",\n",
    "    \"rosetta_hbond_bb_sc\",\n",
    "    \"rosetta_hbond_sc\",\n",
    "    \"rosetta_dslf_fa13\",\n",
    "    \"rosetta_rama_prepro\",\n",
    "    \"rosetta_p_aa_pp\",\n",
    "    \"rosetta_fa_dun\",\n",
    "    \"rosetta_omega\",\n",
    "    \"rosetta_pro_close\",\n",
    "    \"rosetta_yhh_planarity\",\n",
    "    \"aggrescan3d_total_value\",\n",
    "    \"aggrescan3d_avg_value\",\n",
    "    \"aggrescan3d_min_value\",\n",
    "    \"aggrescan3d_max_value\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "df_filtered = df #filter_for_archetypes(df, cath_dict)\n",
    "df_selected_cleaned = df_filtered[selected_columns].dropna()\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_selected_cleaned)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "for architecture_name in df['architecture_name'].unique():\n",
    "    if architecture_name not in selected_architectures:\n",
    "        continue\n",
    "\n",
    "    df_architecture = df[df['architecture_name'] == architecture_name]\n",
    "    df_selected_cleaned = df_architecture[selected_columns].dropna()\n",
    "\n",
    "    if df_selected_cleaned.empty:\n",
    "        print(f\"No data available for {architecture_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    topology_descriptions = df_architecture['topology_description'][df_selected_cleaned.index].reset_index(drop=True)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df_selected_cleaned)\n",
    "\n",
    "    tsne = TSNE(n_components=3, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(scaled_features)\n",
    "    \n",
    "    tsne_df = pd.DataFrame(tsne_results, columns=['Dimension 1', 'Dimension 2', 'Dimension 3'])\n",
    "    tsne_df['topology_description'] = topology_descriptions\n",
    "\n",
    "    # 3D Plotting\n",
    "    fig = plt.figure(figsize=(30, 21))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    codes, uniques = pd.factorize(tsne_df['topology_description'])\n",
    "\n",
    "    num_colors = len(uniques)\n",
    "\n",
    "    repeated_cmap = plt.cm.tab20c(np.linspace(0, 1, num_colors) % 1)\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        tsne_df['Dimension 1'], tsne_df['Dimension 2'], tsne_df['Dimension 3'],\n",
    "        c=[repeated_cmap[i] for i in codes],\n",
    "        s=100\n",
    "    )\n",
    "\n",
    "    legend_handles = [mpatches.Patch(color=repeated_cmap[i], label=uniques[i]) for i in range(num_colors)]\n",
    "\n",
    "    ax.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Topologies\")\n",
    "\n",
    "    ax.set_title(f't-SNE 3D Visualization')\n",
    "    ax.set_xlabel('Dimension 1')\n",
    "    ax.set_ylabel('Dimension 2')\n",
    "    ax.set_zlabel('Dimension 3')\n",
    "\n",
    "    figure_path = os.path.join(base_save_folder, f\"tsne_3d_{architecture_name}.png\")\n",
    "    plt.savefig(figure_path)\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1oai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m             continue_removal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_reduced\n\u001b[0;32m---> 32\u001b[0m df_reduced, dropped_features \u001b[38;5;241m=\u001b[39m \u001b[43mremove_highly_correlated_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduced DataFrame shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_reduced\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropped features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dropped_features)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mremove_highly_correlated_features\u001b[0;34m(df, tolerance)\u001b[0m\n\u001b[1;32m     10\u001b[0m df_reduced \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m dropped_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 13\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf_reduced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mabs()\n\u001b[1;32m     15\u001b[0m continue_removal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m continue_removal:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/frame.py:11036\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11034\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11035\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11036\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11039\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/frame.py:1981\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1980\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1981\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1692\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1751\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1751\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1752\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1oai'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
